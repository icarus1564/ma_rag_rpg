# LLM Provider API Keys
# OpenAI API key (required if using OpenAI provider)
OPENAI_API_KEY=your_openai_api_key_here

# Gemini API key (required if using Gemini provider)
GEMINI_API_KEY=your_gemini_api_key_here

# Ollama configuration (optional, defaults to http://localhost:11434/v1)
OLLAMA_BASE_URL=http://localhost:11434/v1

# Pinecone configuration (required if using Pinecone vector DB)
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-west1-gcp

# Application configuration
LOG_LEVEL=INFO
